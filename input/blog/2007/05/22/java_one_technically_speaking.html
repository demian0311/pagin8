<!--include:header.htm-->
<p>SAP guys gave a session on finding memory leaks.  They used a proprietary SAP tool, very lame.<br /><br />Open source licensing emergency panel was good.  <a href="http://emoglen.law.columbia.edu/">Eben Moglen</a> was a good speaker.  OSI picked <a href="http://www.opensource.org/licenses/category">9 licenses that they recommend for new users</a>.  <a href="http://www.softwarefreedom.org/">Software Freedom Law Center</a> is going to release a guide for developers to help them figure out how to pick licenses. <br /><br />Eben Moglen went over how the LGPL intent is that you can take out the LGPL portion of an application, upgrade and modify it.  So conceivably you could unjar your application, replace the LGPL library and rejar it up.  As long as your users can do this, you're conforming to the LGPL.<br /><br />Sat in a great talk on debugging and improving the quality of code.  The speaker was an author, I forget who.  He recommended some tools to help with debugging and making sure your code is clean.<br /><ul><li><a href="http://pmd.sourceforge.net/">PMD source code analyzer</a>.  You can integrate it with Ant, Maven and many IDEs (including <a href="http://pmd.sourceforge.net/integrations.html#eclipse">Eclipse</a>)</li><li><a href="http://findbugs.sourceforge.net/">FindBugs</a> is similar to PMD, there is overlap but both of them find some stuff the other doesn't.</li><li><a href="http://javapathfinder.sourceforge.net/">Java Path Finder</a>, no specific Ant or Maven support but you can just invoke the Java code from Ant.  Don't forget to include JPF in your classpath along with your classes and set fork=true if you're using it under Ant.  The project came out of NASA and according to their site has actually found problems in real spacecraft software.  JPF verifies your code, how that differs from PMD and FindBugs I'm not sure.</li><li>He recommended this PDF from O'Reilly about <a href="http://www.oreilly.com/catalog/9780596510237/">Checking Java Programs</a>.</li><li>For diagnosing and profiling a running application he recommends  <a href="http://www.glassbox.com">Glassbox</a> and <a href="http://www.jmanage.org/">jManage</a>.</li><li>He noted that JMX (or a combination of AOP and JMX) can be a great tool for monitoring a live application.  Keep counters or otherwise keep track of the internal state.<br /></li><li>Some other things worthy of mention were <a href="http://www.jutils.com/">Lint</a>, <a href="http://ant-contrib.sourceforge.net/tasks/tasks/verifydesign.html">Verify Design</a> and <a href="http://jikes.sourceforge.net/">Jikes</a> (just because it gives better error messages).</li></ul>Rod Johnson gave a talk on Spring.  It was mostly boiler-plate Spring stuff.  He did mention that Spring can dynamically create MBeans for objects if Spring is aware of them.  That's kinda neat.<br /><br />There was a talk on creating manageable systems with JMX, Spring, AOP and Groovy.  There were lots of buzz words but little content.  He did bring home the point that running your application without JMX is like running a car without a speedometer.  He also mentioned using Spring to easily make your objects viewable by JMX.<br /><br />In hallway conversations I learned about a few tools.<br /><ul><li><a href="http://www.opensta.org/">OpenSTA</a> isn't Java specific but it's for heavy HTTP load testing.</li><li><a href="http://faban.sunsource.net/">Faban</a> for benchmarking your application.</li><li><a href="http://rockstarapps.com/pmwiki/pmwiki.php?n=JsLex.JsLex">JsLex</a> for benchmarking AJAX.</li></ul>Chris Richardson (author of <span style="font-style: italic;">POJOs in Action</span>) gave a talk on minimalist testing techniques.  He mostly went through a bunch of best practices.<br /><ul><li>You need fast unit tests, otherwise they won't get run.</li><li>Continuous Integration should handle functional tests (instead of developers having to do them all the time).</li><li>Persistence tier can mock ORM layer, <a href="http://code.google.com/p/ormunit/">ormunit</a>, use an in-memory database like <a href="http://hsqldb.org/">HSQLDB</a>.</li><li>Business tier testing can mock the persistence layer.</li><li>Web testing should leverage <a href="http://cargo.codehaus.org/">cargo</a> for managing containers.  <a href="http://www.mortbay.org/">Jetty</a> is more developer friendly and faster to start.  <a href="http://www.junit.org/index.htm">Junit 4.0</a> and <a href="http://testng.org/doc/">TestNG</a> both have handles for doing something (starting a web container) before all tests are run.  So your tests could efficiently start up a container and deploy an application before all the tests run.</li></ul><span style="font-weight: bold;">Top 10 ways to botch enterprise Java Scalability and Reliability</span> was an entertaining talk.  It was odd because for each thing that he mentioned he also advocated the converse of his assertion.  His point was that you can take any concept too far and none of these points are absolute.  None of the points were very surprising.<br /><ol><li>Avoid proprietary frameworks and APIs.  The point is that depending on what you're using you'll get vendor lock-in but sometimes those proprietary frameworks may integrate and perform better in your environment.</li><li>Assume the network works.  This is a reference to the <a href="http://en.wikipedia.org/wiki/Fallacies_of_Distributed_Computing">Deutsch 8 Fallacies of Distributed Computing</a>.  I interpret this one as, don't forget you are on a network and there is latency.</li><li>Use big JVM heap size.  I think he meant that if you have to tune the heap size there may be something else you should be looking at.</li><li>Use one size fits all architecture.</li><li>Assume disaster recovery can be added when necessary.  I disagree with this one.  I think starting out an application with disaster recovery in mind is a mistake.  Handle all that in the infrastructure; the domain of application server and database gurus.<br /></li><li>Abuse abstractions.  Engineers can always use another layer of abstraction, sometimes this means a performance penalty.</li><li>Introduce single points of bottle-neck or failure.  This makes sense, you have a clustered highly tweaked database but you're running your web-tier on an anemic box.<br /></li><li>Abuse the database.  Realize that not all data needs to be persisted.  Is it not important or temporary.</li><li>Assume you are smarter than the infrastructure.  Often times when you start turning knobs in the name of performance you undermine the capabilities of the infrastructure to do performance improvements.</li><li>Realize that performance doesn't mean scalability.  Scalability is handling many users, performance is speed.</li></ol>I think I would add that maintaining heavy state can be harmful to the ability of your application to scale.  When you try to cluster a heavy state enterprise application the lights dim as all that data is shuffled around to various servers.</p>
<!--include:disqus.htm-->
<!--include:footer.htm-->
